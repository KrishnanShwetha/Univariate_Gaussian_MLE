{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101.02494064  92.20176975 106.91407056  90.02530896  93.97438795\n",
      "  94.96738136 100.48537118  96.49191249 102.13180884 112.09552581\n",
      " 109.54800646 104.58229334  83.09216607 109.15772466  96.68087622\n",
      " 113.00916529  93.49459599 106.71893055 108.97788736  95.51150931\n",
      " 103.16242237 122.11423962 112.87267815 114.49438665 112.94002512\n",
      "  99.11028059 110.02406844 101.30239451  92.62728774 105.83139986\n",
      " 102.51635037 104.03890109  91.83424162 104.60780438 100.79788346\n",
      " 114.31184654  89.87612869 112.5451511  116.14772705  90.56902664\n",
      " 112.59709715  91.800987   118.68368155 113.24400767  87.02357704\n",
      " 119.97843473 125.57456946 105.52965866  99.51654024 116.98578719\n",
      "  87.04582892  97.2608057  108.65820951  93.9376691  100.940792\n",
      " 108.13024905 117.94349837 110.61757801 107.22748762 100.70704542\n",
      "  95.21356086 107.91440154 120.68496144 112.05165561 108.72793506\n",
      " 105.87558909  81.21359362  98.62952924 107.32494927 107.20262223\n",
      "  85.05596587 104.42246275 101.4551929   97.18461028 108.89882909\n",
      " 102.17133564  91.40411605  97.67281887  95.32853061 106.98223065\n",
      "  96.42674586  96.18818676  93.4467384  101.58397652 103.80088214\n",
      "  84.38504224  93.01922101 114.72689972 103.86670175  87.36808334\n",
      " 114.9286752  112.82157856 105.61928791 112.24751994 114.25781161\n",
      "  87.58756704  92.76925977  91.46938791  92.12557538  95.37218518]\n",
      "(100,)\n",
      "sum of xi =  10265.639598061982\n",
      "mu MLE =  102.65639598061982\n",
      "sigma MLE =  9.743253619192298\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load(path):\n",
    "    '''\n",
    "    loads \"MLE_dataset.npy\" given its path into variable 'dataset'. returns 'dataset'\n",
    "    '''\n",
    "    dataset = np.load(path)\n",
    "    print(dataset)\n",
    "    print(dataset.shape)\n",
    "    return dataset\n",
    "    \n",
    "def MLE(dataset):\n",
    "    '''\n",
    "    Input:\n",
    "        dataset - numpy array of shape (100,) - containing the data drawn from unknown gaussian\n",
    "        \n",
    "    Output:\n",
    "        mu - float - MLE estimate of mu based on data\n",
    "        sigma - float - MLE estimate of sigma based on data\n",
    "    '''\n",
    "    mu = 0\n",
    "    sigma = 0\n",
    "    \n",
    "    ''' YOUR CODE HERE '''\n",
    "    sum1 = 0\n",
    "    for xi in dataset:\n",
    "        sum1 = sum1 + xi\n",
    "    print(\"sum of xi = \", sum1)\n",
    "    \n",
    "    mu = (1/100 * sum1)\n",
    "    print(\"mu MLE = \", mu)\n",
    "    \n",
    "    sum2 = 0\n",
    "    for xi in dataset:\n",
    "        square_diff = (xi - mu)**2\n",
    "        sum2 = sum2 + square_diff\n",
    "    \n",
    "    sigma_squared = (1/100) * (sum2)\n",
    "    sigma = (sigma_squared)**(0.5)\n",
    "    print(\"sigma MLE = \", sigma)\n",
    "    \n",
    "    \n",
    "    return mu, sigma\n",
    "\n",
    "''' TEST CODE '''\n",
    "#load dataset. assumes data file is in same directory as code file\n",
    "dataset = load(\"./MLE_dataset.npy\")\n",
    "mu_sigma = MLE(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 78.81841902  59.92615706  71.15229394  90.18538285 118.81056357\n",
      "  80.9280261   45.14860673  97.58525218  99.82685818 103.60648085\n",
      "  74.56142447 120.44294051 109.96856339 109.33562157 121.39386687\n",
      " 132.12320645 119.01362482 103.86431811 112.65306285 112.49130415\n",
      " 120.49681871 133.79556735  81.51823766 113.10472549  77.28585562\n",
      " 115.79644041 132.60652858  74.62238637 125.50005846  92.00858664\n",
      "  82.1365065   91.305633   108.51569113 103.10059454 104.52537838\n",
      "  70.75593518  98.18848329  77.60272436 102.20017597 149.66080717\n",
      " 107.78897394 123.75432832 121.79503352 106.83464033  55.87412126\n",
      "  85.88096629  90.39545188 124.52928731 103.25328869 127.16551708\n",
      "  88.69568952 103.67191054  73.02500763  76.24311558 118.80889005\n",
      " 104.99918136 118.18277123  83.16118628  97.92989942  99.30372256\n",
      "  72.90951305 101.69663965  69.58289515 110.16098078 111.14162068\n",
      "  94.22893581 106.35108113 101.59887673  66.09253744 131.2068784\n",
      " 105.31531227  82.57530387  80.02715952  62.64426538  85.42052644\n",
      "  57.68801553 118.78688028 104.57503535  84.39741913 107.4427868\n",
      " 210.18250014 182.11925573 174.69557    206.18160123 215.83280135\n",
      " 194.1573978  168.07367834 183.51949226 202.01181339 234.42491447\n",
      " 185.50662442 221.99989932 210.87157577 208.55123255 209.77400744\n",
      " 218.22888176 210.8357951  235.49850963 196.21242186 182.29371859\n",
      " 227.63591902 213.21901688 215.83107094 203.27702765 199.34942645\n",
      " 199.64839572 182.74872885 191.2111247  207.56217743 217.36018434\n",
      " 169.62409158 195.02492444 184.29242615 148.16065427 229.60112894\n",
      " 215.01020943 224.28451788 193.04495157 234.79080888 216.13064073\n",
      " 168.34867184 155.0505968  160.21328491 211.5709392  226.79038556\n",
      " 206.90982759 183.98447193 190.37952364 217.13707874 203.99512638\n",
      " 189.95991329 238.29638028 248.49236077 184.5199313  194.03135945\n",
      " 213.78177757 174.74292629 211.88219842 187.87256219 188.25000132\n",
      " 189.4597195  229.79363433 222.53489814 227.02394364 190.39513069\n",
      " 200.35871846 219.20967292 210.37763282 168.3381328  201.20339574\n",
      " 208.83243815 202.52178126 206.62326136 176.11873501 216.56199456\n",
      " 218.77863225 200.45596574 182.35595653 188.43616234 224.12852101\n",
      " 182.61138448 201.11438399 206.1220298  190.69248126 202.90957817\n",
      " 211.78925254 238.8732664  196.68848119 143.0448562  233.00052703\n",
      " 217.92334607 210.11195562 226.62062589 237.76133603 206.91414103\n",
      " 200.37180912 201.20374109 208.05464966 195.45180598 218.43621731\n",
      " 222.48479693 181.70192924 182.62773084 171.79175131 201.91665517\n",
      " 150.36175441 207.37442873 197.25073    163.79278124 200.77471457\n",
      " 189.66763957 212.26539564 160.0530789  164.58371176 197.36493303\n",
      " 204.50853495 211.33389268 162.46471539 206.59931721 199.07841537]\n",
      "k is:  2\n",
      "n_iterations is:  20\n",
      "n_samples is:  200\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load(path):\n",
    "    dataset = np.load(path)\n",
    "    print(dataset)\n",
    "    return dataset\n",
    "\n",
    "def em(dataset, k, n_iterations):\n",
    "    '''\n",
    "    Input:\n",
    "        dataset - np array - containing the data\n",
    "        k - int - representing the number of underlying gaussian distributions\n",
    "        n_iterations - int - representing number of iterations EM should run for\n",
    "        \n",
    "    output:\n",
    "        mus - np array shape (2,) - mus[k] is the EM estimate of the mean of the kth gaussian\n",
    "        sigmas - np array shape (2,) - sigmas[k] is the EM estimate of the stdev of the kth gaussian\n",
    "        pi - np array shape (2,) - pis[j] is the EM estimate of the prior of the kth gaussian\n",
    "    '''\n",
    "    print(\"k is: \",k)\n",
    "    print(\"n_iterations is: \", n_iterations)\n",
    "    n_samples = dataset.shape[0]\n",
    "    print(\"n_samples is: \", n_samples)\n",
    "\n",
    "    # Initial guesses for the parameters DO NOT CHANGE\n",
    "    FINAL_INITIAL_MUS = np.asarray([90, 210]) #DO NOT CHANGE\n",
    "    FINAL_INITIAL_SIGMAS = np.asarray([28,19]) #DO NOT CHANGE\n",
    "    FINAL_INITIAL_PIS = np.asarray([0.3,.7]) #DO NOT CHANGE\n",
    "    pis = FINAL_INITIAL_PIS #DO NOT CHANGE\n",
    "    mus = FINAL_INITIAL_MUS #DO NOT CHANGE\n",
    "    sigmas = FINAL_INITIAL_SIGMAS #DO NOT CHANGE\n",
    "    \n",
    "            \n",
    "    for em_iter in (range(n_iterations)):\n",
    "            #E Step\n",
    "            ''' E STEP CODE '''\n",
    "            # scipy.stats.norm(mean, std).pdf(value)\n",
    "            gaussian_posteriors = []\n",
    "            posterior_k0 = []\n",
    "            posterior_k1 = []\n",
    "            for xi in dataset:\n",
    "                numerator_k0 = (scipy.stats.norm(FINAL_INITIAL_MUS[0],FINAL_INITIAL_SIGMAS[0]).pdf(xi)) * FINAL_INITIAL_PIS[0]\n",
    "                #print(\"numerator_k0 = \", numerator_k0 )\n",
    "                numerator_k1 = (scipy.stats.norm(FINAL_INITIAL_MUS[1],FINAL_INITIAL_SIGMAS[1]).pdf(xi)) * FINAL_INITIAL_PIS[1]\n",
    "                #print(\"numerator_k1 = \", numerator_k1 )\n",
    "                denom_k = (FINAL_INITIAL_PIS[1] * (scipy.stats.norm(FINAL_INITIAL_MUS[1], FINAL_INITIAL_SIGMAS[1]).pdf(xi))) + ((FINAL_INITIAL_PIS[0] * (scipy.stats.norm(FINAL_INITIAL_MUS[0], FINAL_INITIAL_SIGMAS[0]).pdf(xi))))\n",
    "                #print(\"denom_k = \", denom_k)\n",
    "                posterior_k0.append(numerator_k0/denom_k)\n",
    "                posterior_k1.append(numerator_k1/denom_k)\n",
    "                posterior_list = posterior_k0 + posterior_k1  \n",
    "            gaussian_posteriors.append(posterior_list)\n",
    "            \n",
    "            #print(gaussian_posteriors)\n",
    "            #print(\"posterior_list_k0 = \", posterior_list_k0)\n",
    "            #print(\"posterior_list_k1 = \", posterior_list_k1)\n",
    "            \n",
    "            #pass #remove this line when running your code\n",
    "            \n",
    "            '''E STEP CODE END'''\n",
    "            \n",
    "            #M step\n",
    "            ''' M STEP CODE '''\n",
    "            summations = 0\n",
    "            sigma_summations = 0\n",
    "            \n",
    "            for p in range(len(gaussian_posteriors)):\n",
    "                for xindex in range(len(dataset)):\n",
    "                    summations += (dataset[xindex] * gaussian_posteriors[p][xindex])\n",
    "                FINAL_INITIAL_MUS[p] = (summations/np.sum(gaussian_posteriors[p]))\n",
    "                for xindex in range(len(dataset)):\n",
    "                    sigma_summations += ((dataset[xindex] - FINAL_INITIAL_MUS[p] ) * gaussian_posteriors[p][xindex])**(2)\n",
    "                FINAL_INITIAL_SIGMAS[p] = ((sigma_summations/np.sum(gaussian_posteriors[p]))**(0.5))\n",
    "                FINAL_INITIAL_PIS[p] = (np.sum(gaussian_posteriors[p])/n_samples)\n",
    "                summations = 0\n",
    "                sigma_summations = 0\n",
    "                \n",
    "            # find log derivation how???\n",
    "            # updates on sigma ??\n",
    "            # same values in all 20 interations ???\n",
    "            \n",
    "            #print(pis, mus, sigmas)\n",
    "            \n",
    "            \n",
    "            '''M STEP CODE END'''\n",
    "\n",
    "    return pis, mus, sigmas\n",
    "\n",
    "def main():\n",
    "    \n",
    "    n_iterations = 20 #DO NOT CHANGE\n",
    "    k = 2 #DO NOT CHANGE\n",
    "    \n",
    "    ''' TEST CODE '''\n",
    "    #load dataset. assumes data file is in same directory as code file\n",
    "    dataset = np.load(\"EM_dataset.npy\")\n",
    "    load(\"EM_dataset.npy\")\n",
    "    pis, mus, sigmas = em(dataset, k, n_iterations)\n",
    "\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
